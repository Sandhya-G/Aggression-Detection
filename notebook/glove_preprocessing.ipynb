{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandhya/anaconda3/lib/python3.7/site-packages/tqdm/std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../paths.py\n",
    "CONST = CONST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12761</td>\n",
       "      <td>Mannnnnn these hoes aint loyal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>25141</td>\n",
       "      <td>have a fabulous weekend beautiful souls #nofil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>53167</td>\n",
       "      <td>#fathersday #dad @user</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>17294</td>\n",
       "      <td>RT @SheswantstheD: these hoes ain't loyal http...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>29359</td>\n",
       "      <td>newhairâ¨ð #lapis#rollen#new#hair#brond#gr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              tweet  class\n",
       "0       12761                     Mannnnnn these hoes aint loyal      1\n",
       "1       25141  have a fabulous weekend beautiful souls #nofil...      0\n",
       "2       53167                            #fathersday #dad @user       0\n",
       "3       17294  RT @SheswantstheD: these hoes ain't loyal http...      1\n",
       "4       29359  newhairâ¨ð #lapis#rollen#new#hair#brond#gr...      0"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(CONST.TRAIN_DATA)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12761</td>\n",
       "      <td>Mannnnnn these hoes aint loyal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>25141</td>\n",
       "      <td>have a fabulous weekend beautiful souls #nofil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>53167</td>\n",
       "      <td>#fathersday #dad @user</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>17294</td>\n",
       "      <td>RT @SheswantstheD: these hoes ain't loyal http...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>29359</td>\n",
       "      <td>newhairâ¨ð #lapis#rollen#new#hair#brond#gr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              tweet  class\n",
       "0       12761                     Mannnnnn these hoes aint loyal      1\n",
       "1       25141  have a fabulous weekend beautiful souls #nofil...      0\n",
       "2       53167                            #fathersday #dad @user       0\n",
       "3       17294  RT @SheswantstheD: these hoes ain't loyal http...      1\n",
       "4       29359  newhairâ¨ð #lapis#rollen#new#hair#brond#gr...      0"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_copy = train.copy()\n",
    "train_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/processing/glove_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embed = load_embed(CONST.GLOVE_100d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, False, True, True)"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'<user>' in glove_embed, '<number>' in glove_embed, '<c>' in glove_embed, '<repeat>' in glove_embed,\"<allcaps>\" in glove_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42364/42364 [00:00<00:00, 48870.48it/s]\n",
      "100%|██████████| 97055/97055 [00:00<00:00, 228926.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 20.63% of vocab\n",
      "Found embeddings for  67.83% of all text\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab(list(train_copy['tweet'].apply(lambda x:x.split())))\n",
    "vocab\n",
    "oov = check_coverage(vocab,glove_embed)\n",
    "#oov[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 0 words to embedding\n"
     ]
    }
   ],
   "source": [
    "add_lower(glove_embed, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glove_embed['us']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/processing/html_tag_remover.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy['tweet'] = train_copy['tweet'].apply(lambda x : strip_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " joke: what do you call a pig with three eyes? <repeat> piiig! <repeat> allcaps <allcaps>  . <repeat>  <number> <number> \n"
     ]
    }
   ],
   "source": [
    "%run ../src/processing/regular_expressions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy['tweet'] = train_copy['tweet'].apply(lambda x: tweet_preprocessing(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42364/42364 [00:00<00:00, 55617.74it/s]\n",
      "100%|██████████| 65444/65444 [00:00<00:00, 226897.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 41.40% of vocab\n",
      "Found embeddings for  86.78% of all text\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab(list(train_copy['tweet'].apply(lambda x:x.split())))\n",
    "#vocab\n",
    "oov = check_coverage(vocab,glove_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"i'm\", 1946),\n",
       " (\"don't\", 1635),\n",
       " ('“', 1234),\n",
       " (\"can't\", 982),\n",
       " (\"ain't\", 712),\n",
       " (\"you're\", 651),\n",
       " ('bihday', 584),\n",
       " ('bitch.', 509),\n",
       " (\"y'all\", 353),\n",
       " (\"i'll\", 270)]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:10]\n",
    "#%run ../src/processing/contractions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy['tweet'] = train_copy['tweet'].apply(lambda x: clean_contractions(x, contraction_mapping))\n",
    "#train_copy.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42364/42364 [00:00<00:00, 63905.42it/s]\n",
      "100%|██████████| 65351/65351 [00:00<00:00, 157328.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 41.44% of vocab\n",
      "Found embeddings for  88.38% of all text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab(list(train_copy['tweet'].apply(lambda x:x.split())))\n",
    "#vocab\n",
    "oov = check_coverage(vocab,glove_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('“', 1234),\n",
       " ('bihday', 584),\n",
       " ('bitch.', 509),\n",
       " ('😂', 224),\n",
       " ('day!', 222),\n",
       " ('bitch,', 200),\n",
       " ('…', 193),\n",
       " ('<url>”', 163),\n",
       " ('trash.', 155),\n",
       " ('😂😂', 145)]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'s  'fathers,mothers,brothers,sisters,babys fathers also uncle\""
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def ap(text):\n",
    "    text = text.group()\n",
    "    return text.replace(\"'\",\"\")\n",
    "re.sub(\"\\w+[']s\",ap,\"'s  'father's,mother's,brother's,sister's,baby's father's also uncle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/processing/spellings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy['tweet'] = train_copy['tweet'].apply(lambda x: replace_elongated_text(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42364/42364 [00:01<00:00, 38181.23it/s]\n",
      "100%|██████████| 64895/64895 [00:00<00:00, 168517.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 41.80% of vocab\n",
      "Found embeddings for  88.46% of all text\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab(list(train_copy['tweet'].apply(lambda x:x.split())))\n",
    "#vocab\n",
    "oov = check_coverage(vocab,glove_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('“', 1234),\n",
       " ('bihday', 584),\n",
       " ('bitch.', 509),\n",
       " ('😂😂', 379),\n",
       " ('😂', 224),\n",
       " ('day!', 222),\n",
       " ('bitch,', 200),\n",
       " ('…', 193),\n",
       " ('<url>”', 163),\n",
       " ('trash.', 155)]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/processing/special_char.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy['tweet'] = train_copy['tweet'].apply(lambda x: clean_special_chars(x,punct,punct_mapping))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42364/42364 [00:00<00:00, 45451.50it/s]\n",
      "100%|██████████| 47082/47082 [00:00<00:00, 196901.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 62.03% of vocab\n",
      "Found embeddings for  96.45% of all text\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab(list(train_copy['tweet'].apply(lambda x:x.split())))\n",
    "#vocab\n",
    "oov = check_coverage(vocab,glove_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bihday', 636),\n",
       " ('😂😂', 447),\n",
       " ('😂', 270),\n",
       " ('â\\x9d¤ï¸\\x8f', 122),\n",
       " ('★', 121),\n",
       " ('ð\\x9f\\x98\\x8a', 116),\n",
       " ('ð\\x9f\\x98\\x8d', 103),\n",
       " ('ð\\x9f\\x98', 86),\n",
       " ('😒', 82),\n",
       " ('ð\\x9f\\x98\\x82', 73)]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smiling_face fmgvmn steaming_bowl  sleeping_face  exploding_head  woozy_face fgfb thinking_face\n"
     ]
    }
   ],
   "source": [
    "%run ../src/processing/emojis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_copy['removed_contr'][len('removed_contr')<0]\n",
    "#train_copy.head()\n",
    "drop_rows = train_copy[train_copy['tweet']==\"\"].tweet\n",
    "train_copy.drop(drop_rows.index, axis=0,inplace=True)\n",
    "#train_copy.drop([[1859]],inplace=True)\n",
    "train_copy['tweet'] = train_copy['tweet'].apply(lambda x: remove_duplicates(x) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42348/42348 [00:01<00:00, 36388.31it/s]\n",
      "100%|██████████| 46972/46972 [00:00<00:00, 192029.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 62.18% of vocab\n",
      "Found embeddings for  96.45% of all text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab(list(train_copy['tweet'].apply(lambda x:x.split())))\n",
    "#vocab\n",
    "oov = check_coverage(vocab,glove_embed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('😂', 717),\n",
       " ('bihday', 636),\n",
       " ('â\\x9d¤ï¸\\x8f', 122),\n",
       " ('★', 121),\n",
       " ('ð\\x9f\\x98\\x8a', 116),\n",
       " ('ð\\x9f\\x98\\x8d', 103),\n",
       " ('😒', 90),\n",
       " ('😭', 88),\n",
       " ('ð\\x9f\\x98', 86),\n",
       " ('ð\\x9f\\x98\\x82', 73)]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "white_list = string.ascii_letters + string.digits + ' '\n",
    "white_list += \"'\"\n",
    "#oov[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1193534/1193534 [00:02<00:00, 502976.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'.:,!\"?()-/*>^<&_~;|[]`$=+%@\\\\#}{'"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_chars = ''.join([c for c in tqdm(glove_embed) if len(c) == 1])\n",
    "glove_symbols = ''.join([c for c in glove_chars if not c in white_list])\n",
    "glove_symbols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42348/42348 [00:01<00:00, 23162.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ð\\x9f\\x98â\\x9c¨\\x92\\x87\\x80¦👏\\x86\\x9d\\x93\\x99\\x8f\\x8e\\x89¤ï¸😩😂¬\\x8a\\x90¶¾😭\\x9e\\x95😅💊👫❤½✌️★\\x8d\\x8b»\\x84\\x8c¹👋\\x96😳\\xad\\x82©®👀😏ó\\x94😋😌¼✂😻🙌💦😎👌🙅✋🚫🍞💁😪ª\\x9a\\x91«🙏\\x81ã👟\\x9b\\x88\\x97💯¢¥😷¡\\x83😕😍😒º💀😢😴\\U000feb9f¿👊💸😖🙈¯💩ìíè🆗🆒äçåµñ⊕🙊👅🎵ü😈🍻🎉🎈😊🔫☺👬👭💥§😆♥◡̈⃝😉😜é😫🐸☕😁😱‼💙💃🎤👐🌈🎭😘💍💕🔐✊💋🔪±😹\\ue412🐛💰·✈�ëê😐😡👉👈🔴⚫👎😑💜❗👼😔æ→👩👆👯😝🐎\\U000feb97\\ue411\\ue427🏆📝📃🏀🐼💅😤📑😠🐱😶🍟á😃📖û👑👿\\U000fe343😥🍇🍼😛🚮💖😺✨🌟💫😞🎂🍰🍑💑💆😣🎄⛄🎅🙋🍁\\U000fe35b\\U000feb5d\\U000fe358\\U000feb7b\\U000fe334\\U000fec11\\U000feb9d💎👍💵🚨💧🐢😦🙇🌵👸💞🔥💨🎼🎁🌴☀🙎\\U000feb9e💄💗🔑👶🚼☝🎲⃣🐥🐣😾。🚌🙆💏🚶\\U000fe32c🎶🎧🙉😿øù💡🍅😟🐷📰😓🐊💪😮🇺🇸\\U000fe326❓⭐🍍ö😵🐦🐝🐯🍃🌿\\ue31f\\ue301📕📚🏡😬🙀ò💤😨👄🎬🎥\\U000feba0💛🌙☁🌠🆚👻🏈😗😄\\U000fe346\\U000feb0f💚🎊\\U000fe33a⚡👮💲📢⛽⚾🍂🚙\\U000fe327👇🚕⚪\\ue40d\\ue04f\\ue40c\\ue107🐙🍄✔💣🍆😲🕛′🍗♿🇬🇧😧🏄🍪❄🌀📣👰\\ue108👧💢🇮🇹✖\\U000feb5b\\U000fe321🍺👷🌝🏃🎯👂🐬🐐\\U000fe194\\U000fe355❌⭕🌹👞🙍˘🐤👠👛💳🍉😽⬇🏂😰👺🚧🗿🌊🏊😇î♨🔊🍕ú♫\\U000fe511\\U000fe4e4\\U000fe4dd🌾🔚\\ue41f🐠❕🚬🍸\\U000fe190♡❔\\U000fe4f5🌸🚓🚒💺🍖🍝🍤🍛📷💔👹😚\\U000fe320💓💇👵💉🐈🐶😼🚀⌚💂💭🍫🐒\\U000fe351\\U000fe335😯👲🚘🚩🌽💘📋\\U000fe340🌳\\U000fe825\\U000feb99\\U000fe347🍵🚥🏰\\ue40e\\ue24d\\ue337👽🔓\\U000feb5c🅰🐺📼🐍łę⏳🐂，\\ue420🍩👙📉🌚'"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_characters = build_vocab(list(train_copy[\"tweet\"]))\n",
    "all_characters\n",
    "#symbols_to_delete = ''.join([c for c in all_characters if not c in white_list if not c in glove_symbols])\n",
    "#symbols_to_delete\n",
    "del all_characters[\"<\"]\n",
    "del all_characters[\">\"]\n",
    "all_characters\n",
    "symbols_to_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dict = {ord(c):f'' for c in symbols_to_delete}\n",
    "isolate_dict = {ord(c):f' {c} ' for c in symbols_to_isolate}\n",
    "\n",
    "def handle_punctuation(x):\n",
    "    x = x.translate(remove_dict)\n",
    "    x = x.translate(isolate_dict)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy['tweet'] = train_copy['tweet'].apply(lambda x: handle_punctuation(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42348/42348 [00:01<00:00, 37668.25it/s]\n",
      "100%|██████████| 40761/40761 [00:00<00:00, 186036.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 72.19% of vocab\n",
      "Found embeddings for  98.05% of all text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab(list(train_copy['tweet'].apply(lambda x:x.split())))\n",
    "#vocab\n",
    "oov = check_coverage(vocab,glove_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"!!\" in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "':#.,!-\"/?&~*=@$;%+(|)^{}\\\\[]'"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols_to_isolate = ''.join([c for c in all_characters  if c not in white_list if c in glove_symbols])\n",
    "symbols_to_isolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ASAP\" in glove_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CONST.TRAIN_DATA)\n",
    "df.head()\n",
    "df_copy1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " what do you call a pig with three eyes? <repeat> piiig! <repeat> allcaps <allcaps>  . <repeat> [dbr <number> !@ <number> <number> \n",
      "dfvfe ffve rfvfe sdv eee\n",
      "dfvfe ffve rfvfe sdv eee\n",
      "talk to you later wait\n",
      " what do you call a pig with three eyes? <repeat> piiig! <repeat> allcaps <allcaps>  . <repeat> [dbr <number> !@ <number> <number> \n"
     ]
    }
   ],
   "source": [
    "%run ../src/processing/regular_expressions.py\n",
    "%run ../src/processing/special_char.py\n",
    "%run ../src/processing/cleaning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9228c52e07214289b6933220910ba925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42364), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9baf190685864dd587acf45389fa449b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42364), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "656237246ea44bc3b18c3e39f6401a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42364), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5279cb598a4a678dfab7a55359fe89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42364), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7f05e2433c4bda838d099efd36fe1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42364), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea3bdfe86fa48758cce3a620e698105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42364), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c57960ceb8842ec95e06eda49e3f977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42364), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "d=clean_data(df_copy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42364/42364 [00:00<00:00, 117164.37it/s]\n",
      "100%|██████████| 28732/28732 [00:00<00:00, 333001.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 83.58% of vocab\n",
      "Found embeddings for  98.67% of all text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "drop_rows = d[d['tweet']==\"\"]\n",
    "d.drop(drop_rows.index, axis=0,inplace=True)\n",
    "vocab = build_vocab(list(d['tweet'].apply(lambda x:x.split())))\n",
    "#vocab\n",
    "oov = check_coverage(vocab,glove_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  mann these hoes aint loyal\n",
       "1    have a fabulous weekend beautiful souls \n",
       "2                                            \n",
       "3                    these hoes is not loyal \n",
       "4                                  newhair l \n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bihday', 451),\n",
       " ('staing', 54),\n",
       " ('erience', 53),\n",
       " ('impoant', 49),\n",
       " ('staed', 43),\n",
       " ('toptags', 27),\n",
       " ('ected', 23),\n",
       " ('unfounately', 20),\n",
       " ('suppoers', 19),\n",
       " ('suppoing', 19),\n",
       " ('ectations', 19),\n",
       " ('fuher', 17),\n",
       " ('ensive', 17),\n",
       " ('cultureofdevelopment', 17),\n",
       " ('ukhxint', 16),\n",
       " (\"fuckin'\", 16),\n",
       " ('osed', 15),\n",
       " ('nothe', 15),\n",
       " ('spos', 15),\n",
       " ('brexit', 13),\n",
       " ('muzzie', 13),\n",
       " ('aicle', 12),\n",
       " ('paner', 12),\n",
       " ('oppounity', 11),\n",
       " ('factsguide', 11),\n",
       " ('heabreaking', 10),\n",
       " ('ceain', 10),\n",
       " ('soed', 10),\n",
       " ('appletstag', 9),\n",
       " ('eriences', 9),\n",
       " ('lains', 9),\n",
       " ('livelypics', 9),\n",
       " ('woulday', 9),\n",
       " (\"'i\", 9),\n",
       " ('bihdays', 8),\n",
       " ('polarisation', 8),\n",
       " ('leftright', 8),\n",
       " ('wakeuppeopl', 8),\n",
       " ('summeime', 8),\n",
       " (\"gon'\", 8),\n",
       " ('yelchin', 8),\n",
       " ('ecting', 8),\n",
       " ('heabroken', 8),\n",
       " ('fleek', 8),\n",
       " ('kscrashcorrectors', 8),\n",
       " ('osing', 7),\n",
       " ('jivemap', 7),\n",
       " ('staer', 7),\n",
       " ('oppounities', 7),\n",
       " ('suppoer', 7),\n",
       " ('nohern', 7),\n",
       " ('altright', 7),\n",
       " (\"day'\", 7),\n",
       " ('giphy', 7),\n",
       " ('bihdaysway', 6),\n",
       " ('miscegenation', 6),\n",
       " ('quotestagsapp', 6),\n",
       " ('blicqer', 6),\n",
       " ('caoon', 6),\n",
       " ('ofay', 6),\n",
       " ('aists', 6),\n",
       " ('cochair', 6),\n",
       " ('libey', 6),\n",
       " ('repoer', 6),\n",
       " ('regrann', 6),\n",
       " ('enteainment', 6),\n",
       " (\"'bout\", 6),\n",
       " ('erienced', 6),\n",
       " ('coolestlifehack', 6),\n",
       " ('poman', 6),\n",
       " ('mindsconsole', 6),\n",
       " ('squak', 5),\n",
       " ('thweeksary', 5),\n",
       " ('mytraining', 5),\n",
       " ('honkie', 5),\n",
       " ('muzzies', 5),\n",
       " ('ression', 5),\n",
       " ('officebearers', 5),\n",
       " ('friyay', 5),\n",
       " ('ressing', 5),\n",
       " ('ceainly', 5),\n",
       " (\"'happy\", 5),\n",
       " ('stockboy', 5),\n",
       " ('blaxican', 5),\n",
       " (\"victims'\", 5),\n",
       " ('apament', 5),\n",
       " ('lained', 5),\n",
       " ('thincc', 5),\n",
       " ('fouh', 5),\n",
       " ('paicipate', 5),\n",
       " ('selfserving', 5),\n",
       " (\"nothin'\", 5),\n",
       " ('flcrashcorrectors', 5),\n",
       " ('bihdaykazuki', 4),\n",
       " ('suppoive', 4),\n",
       " ('barbiets', 4),\n",
       " (\"fathers'\", 4),\n",
       " (\"'you\", 4),\n",
       " ('bdayspl', 4),\n",
       " ('intermarket', 4)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#can use spellchecker to increase the coverage\n",
    "oov[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"<user>\" in glove_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
