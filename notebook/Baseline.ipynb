{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandhya/Project/final/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "import ipywidgets\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import model_selection\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jupyter nbextension enable --py --sys-prefix widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../paths.py\n",
    "CONST = CONST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(CONST.TRAIN_DATA)\n",
    "test_data = pd.read_csv(CONST.TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(train_data.columns[0],axis=1,inplace=True)\n",
    "test_data.drop(test_data.columns[0],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mannnnnn these hoes aint loyal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>have a fabulous weekend beautiful souls #nofil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#fathersday #dad @user</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @SheswantstheD: these hoes ain't loyal http...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>newhairâ¨ð #lapis#rollen#new#hair#brond#gr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  class\n",
       "0                     Mannnnnn these hoes aint loyal      1\n",
       "1  have a fabulous weekend beautiful souls #nofil...      0\n",
       "2                            #fathersday #dad @user       0\n",
       "3  RT @SheswantstheD: these hoes ain't loyal http...      1\n",
       "4  newhairâ¨ð #lapis#rollen#new#hair#brond#gr...      0"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What I look like ho? I look like YES and you l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user lots of #resistance and #challenges fro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what's wrong with ppl nowadays? i was conducti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Montulos Lakers are trash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>will be playing rf simpson in #singinintherain...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  class\n",
       "0  What I look like ho? I look like YES and you l...      1\n",
       "1   @user lots of #resistance and #challenges fro...      0\n",
       "2  what's wrong with ppl nowadays? i was conducti...      0\n",
       "3                         @Montulos Lakers are trash      1\n",
       "4  will be playing rf simpson in #singinintherain...      0"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1,2),max_features=10000)\n",
    "train_tfidf = vec.fit_transform(train_data.tweet)\n",
    "test_tfidf = vec.transform(test_data.tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42364, 10000)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = naive_bayes.MultinomialNB()\n",
    "clf.fit(train_tfidf,train_data[\"class\"])\n",
    "predictions = clf.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8971119133574007"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(test_data['class'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/processing/html_tag_remover.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986d645760b54637aff85f26df4f55d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42364.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60545e7381e04d29a055a029aadf7a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11949.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data[\"tweet\"] = train_data[\"tweet\"].progress_apply(lambda x: strip_tags(x))\n",
    "test_data[\"tweet\"] = test_data[\"tweet\"].progress_apply(lambda x: strip_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896964856230032"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1,2),max_features=10000)\n",
    "train_tfidf = vec.fit_transform(train_data.tweet)\n",
    "test_tfidf = vec.transform(test_data.tweet)\n",
    "clf.fit(train_tfidf,train_data[\"class\"])\n",
    "predictions = clf.predict(test_tfidf)\n",
    "metrics.f1_score(test_data['class'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dropna(inplace=True)\n",
    "test_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "talk to you later wait\n"
     ]
    }
   ],
   "source": [
    "%run ../src/processing/contractions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452950fd6029493793a5c8ceadf20a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42364.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4520e64554c417dab98e11f14573662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11949.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data['tweet'] = train_data['tweet'].progress_apply(lambda x: replace_slang(x))\n",
    "test_data['tweet'] = test_data['tweet'].progress_apply(lambda x: replace_slang(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1a0efd9418425ba4f05e98b7fd6027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42364.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0465b20cb78845189e941e3c45c6aa63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11949.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data['tweet'] = train_data['tweet'].progress_apply(lambda x: clean_contractions(x))\n",
    "test_data['tweet'] = test_data['tweet'].progress_apply(lambda x: clean_contractions(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8927328760314146"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1,2),max_features=10000)\n",
    "train_tfidf = vec.fit_transform(train_data.tweet)\n",
    "test_tfidf = vec.transform(test_data.tweet)\n",
    "clf.fit(train_tfidf,train_data[\"class\"])\n",
    "predictions = clf.predict(test_tfidf)\n",
    "metrics.f1_score(test_data['class'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/processing/glove_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "word,frequency = get_top_n_words(25,vec,train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <hashtags>: what do you… … call a pig with three eyes???piiig!!!allcaps <allcaps>  .... full time time\n"
     ]
    }
   ],
   "source": [
    "%run ../src/processing/regular_expressions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dropna(inplace=True)\n",
    "test_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91cbed34c23e40b0a2b1d8ff1ddf7167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42364.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa23145c047413ba5f00b0cc855e5af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11949.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data['tweet'] = train_data['tweet'].progress_apply(lambda x: tweet_preprocessing(x))\n",
    "test_data['tweet'] = test_data['tweet'].progress_apply(lambda x: tweet_preprocessing(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b26259487cb407a9c12ffd023d2a13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42364.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e68cde4a2ba4ed7879ee6c528dd089a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42364.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9cfa6946e14443ab09294c65c91a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42364.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data[\"hashtags\"] = train_data[\"tweet\"].progress_apply(lambda comment: comment.count('<hashtags>'))\n",
    "train_data[\"user\"] = train_data[\"tweet\"].progress_apply(lambda comment: comment.count(\"<user>\"))\n",
    "train_data[\"allcaps\"]  = train_data[\"tweet\"].progress_apply(lambda comment: comment.count(\"<allcaps>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa565fb0573141b49c93e66d6a242195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11949.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7a80617b6441e690b7ccc908480078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11949.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff15e0b0ac445db9bb0fbda5368f011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11949.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_data[\"hashtags\"] = test_data[\"tweet\"].progress_apply(lambda comment: comment.count('<hashtags>'))\n",
    "test_data[\"user\"] = test_data[\"tweet\"].progress_apply(lambda comment: comment.count(\"<user>\"))\n",
    "test_data[\"allcaps\"]  = test_data[\"tweet\"].progress_apply(lambda comment: comment.count(\"<allcaps>\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efddcb92e1a5459b885cf22097d6b35c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42364.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19444f6ad5d548208c700da3506e9b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11949.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data[\"tweet\"] = train_data[\"tweet\"].progress_apply(lambda comment: re.sub(r\"(<hashtags>|<user>|<allcaps>)\",\" \", comment))\n",
    "test_data[\"tweet\"] = test_data[\"tweet\"].progress_apply(lambda comment: re.sub(r\"(<hashtags>|<user>|<allcaps>)\",\" \", comment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39067ce57b64c468f531eefcd33ffbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42364.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b368d94674e49988e8cd84bcbbe06da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11949.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data[\"tweet\"] = train_data[\"tweet\"].progress_apply(lambda comment: re.sub(r\"\\s+\",\" \", comment))\n",
    "test_data[\"tweet\"] = test_data[\"tweet\"].progress_apply(lambda comment: re.sub(r\"\\s+\",\" \", comment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.881002931958346"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1,2),max_features=10000)\n",
    "train_tfidf = vec.fit_transform(train_data.tweet)\n",
    "test_tfidf = vec.transform(test_data.tweet)\n",
    "clf.fit(train_tfidf,train_data[\"class\"])\n",
    "predictions = clf.predict(test_tfidf)\n",
    "metrics.f1_score(test_data['class'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "word,frequency = get_top_n_words(25,vec,train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopwords = ['the','to','and','is','my','just','us','its','it','up','in','for','of','not','at','this','on','am','that','be','with','are','me','it','all','like','so','do','rt','ff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['tweet'] = train_data['tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "test_data['tweet'] = test_data['tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dropna(inplace=True)\n",
    "test_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_rows = train_data[train_data['tweet']==\"\"]\n",
    "train_data.drop(drop_rows.index, axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_rows = test_data[test_data['tweet']==\"\"]\n",
    "test_data.drop(drop_rows.index, axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/processing/spellings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67281b321e1e4ade87e00d2448426642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42306.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3eee3970f414d7093e57dbb509cece3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11935.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data['tweet'] = train_data['tweet'].progress_apply(lambda x: replace_elongated_text(x))\n",
    "test_data['tweet'] = test_data['tweet'].progress_apply(lambda x: replace_elongated_text(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8874158678360188"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1,2),max_features=10000)\n",
    "train_tfidf = vec.fit_transform(train_data.tweet)\n",
    "test_tfidf = vec.transform(test_data.tweet)\n",
    "clf.fit(train_tfidf,train_data[\"class\"])\n",
    "predictions = clf.predict(test_tfidf)\n",
    "metrics.f1_score(test_data['class'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "word,frequency = get_top_n_words(25,vec,train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/processing/emojis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f118b36f49f4d1988ac052e17bee6f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42306.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a54b77d4e154b999b4b7ad2950d24ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11935.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data['tweet'] = train_data['tweet'].progress_apply(lambda x: replace_emojis_with_text(x))\n",
    "test_data['tweet'] = test_data['tweet'].progress_apply(lambda x: replace_emojis_with_text(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8860267811509762"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1,2),max_features=10000)\n",
    "train_tfidf = vec.fit_transform(train_data.tweet)\n",
    "test_tfidf = vec.transform(test_data.tweet)\n",
    "clf.fit(train_tfidf,train_data[\"class\"])\n",
    "predictions = clf.predict(test_tfidf)\n",
    "metrics.f1_score(test_data['class'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fdf4480ba304ab69526053b53693804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42306.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43faa19cb23d48659cb9cb7f78e88a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42306.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e85083fbec14503b3ad99ace2f69b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42306.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1a2b3909ca49d4b57c305aada8955c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42306.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data['num_exclamation_marks'] = train_data['tweet'].progress_apply(lambda comment: comment.count('!'))\n",
    "train_data['num_question_marks'] = train_data['tweet'].progress_apply(lambda comment: comment.count('?'))\n",
    "train_data['num_punctuation'] = train_data['tweet'].progress_apply(lambda comment: sum(comment.count(w) for w in '.,;:'))\n",
    "train_data['num_symbols'] = train_data['tweet'].progress_apply(lambda comment: sum(comment.count(w) for w in '*&$%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84935c6b1bf341558d2c60557c033cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11935.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7709365c6c45b59c738d46a8836613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11935.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107a213e0a434a5d9ba54e9da9e9da18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11935.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e17fe9b343194625a20a805ed71a59b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11935.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_data['num_exclamation_marks'] = test_data['tweet'].progress_apply(lambda comment: comment.count('!'))\n",
    "test_data['num_question_marks'] = test_data['tweet'].progress_apply(lambda comment: comment.count('?'))\n",
    "test_data['num_punctuation'] = test_data['tweet'].progress_apply(lambda comment: sum(comment.count(w) for w in '.,;:'))\n",
    "test_data['num_symbols'] = test_data['tweet'].progress_apply(lambda comment: sum(comment.count(w) for w in '*&$%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfvfe ffve rfvfe sdv eee\n"
     ]
    }
   ],
   "source": [
    "%run ../src/processing/special_char.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6999a5a648741babf112bb24f374e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42306.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74ea8dc0d5f47449949fd50a525ee8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11935.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data['tweet'] = train_data['tweet'].progress_apply(lambda x: clean_special_chars(x))\n",
    "test_data['tweet'] = test_data['tweet'].progress_apply(lambda x: clean_special_chars(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6345c457eeaa4ea49a99e88b62b5b9c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42210.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fbbd3e0a9b449b7b1552a09a15f3174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42210.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03617b0d4b1349a7ad11b757a13c3e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42210.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e019b998eb4a51a81f70e52a9c0745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42210.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data['total_length'] = train_data['tweet'].progress_apply(len)\n",
    "train_data['capitals'] = train_data['tweet'].progress_apply(lambda comment: sum(1 for c in comment if c.isupper()))\n",
    "train_data['caps_vs_length'] =  train_data['capitals']/train_data['total_length']\n",
    "train_data['num_words'] = train_data['tweet'].progress_apply(lambda comment: len(comment.split()))\n",
    "train_data['num_unique_words'] = train_data['tweet'].progress_apply(lambda comment: len(set(w for w in comment.split())))\n",
    "train_data['words_vs_unique'] = train_data['num_unique_words'] / train_data['num_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18cd93dc9564452d8d7e406af5275990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11886.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bbfdfdccfe4485abc78de824ab71391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11886.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "353029dbc95340de9a141da825e3253a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11886.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9168eda90047bb89415a7aae0175cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11886.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_data['total_length'] = test_data['tweet'].progress_apply(len)\n",
    "test_data['capitals'] = test_data['tweet'].progress_apply(lambda comment: sum(1 for c in comment if c.isupper()))\n",
    "test_data['caps_vs_length'] =  test_data['capitals']/test_data['total_length']\n",
    "test_data['num_words'] = test_data['tweet'].progress_apply(lambda comment: len(comment.split()))\n",
    "test_data['num_unique_words'] = test_data['tweet'].progress_apply(lambda comment: len(set(w for w in comment.split())))\n",
    "test_data['words_vs_unique'] = test_data['num_unique_words'] / train_data['num_words']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tweet \n",
      "\n",
      "bitch                                                                                          25\n",
      "pussy                                                                                          25\n",
      "update                                                                                         24\n",
      "fathers day                                                                                    17\n",
      "always                                                                                         16\n",
      "                                                                                               ..\n",
      "last walk beach before heading home tomorrow  sanibel                                           1\n",
      "damn you directtv blackout yankee game a freaking walk off  !  you killing satellite douche     1\n",
      "only school wouldnt give kids their schedules                                                   1\n",
      "i herd most random and creepiest sound da fuck going outside windows i looking out bitch        1\n",
      "hate when bitches long hair decide get a haircut nothin good ever comes out                     1\n",
      "Name: tweet, Length: 40720, dtype: int64\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " class \n",
      "\n",
      "0    24566\n",
      "1    17644\n",
      "Name: class, dtype: int64\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " hashtags \n",
      "\n",
      "0     24210\n",
      "1      5585\n",
      "2      3874\n",
      "3      2471\n",
      "4      1799\n",
      "5      1463\n",
      "6       988\n",
      "7       714\n",
      "8       461\n",
      "9       324\n",
      "10      146\n",
      "11       81\n",
      "12       50\n",
      "13       20\n",
      "14       18\n",
      "16        4\n",
      "15        1\n",
      "20        1\n",
      "Name: hashtags, dtype: int64\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " user \n",
      "\n",
      "0     22787\n",
      "1     13783\n",
      "2      3700\n",
      "3      1242\n",
      "4       401\n",
      "5       152\n",
      "6        81\n",
      "7        31\n",
      "8        22\n",
      "9         9\n",
      "10        2\n",
      "Name: user, dtype: int64\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " allcaps \n",
      "\n",
      "0     40399\n",
      "1      1263\n",
      "2       246\n",
      "3        98\n",
      "4        65\n",
      "5        57\n",
      "8        25\n",
      "6        22\n",
      "7        15\n",
      "10        5\n",
      "9         4\n",
      "11        4\n",
      "12        2\n",
      "14        2\n",
      "17        1\n",
      "13        1\n",
      "25        1\n",
      "Name: allcaps, dtype: int64\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " num_exclamation_marks \n",
      "\n",
      "0    34731\n",
      "1     4621\n",
      "2     2262\n",
      "3      349\n",
      "4      183\n",
      "5       31\n",
      "6       27\n",
      "8        3\n",
      "7        3\n",
      "Name: num_exclamation_marks, dtype: int64\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " num_question_marks \n",
      "\n",
      "0    39149\n",
      "1     2530\n",
      "2      441\n",
      "3       53\n",
      "4       28\n",
      "5        5\n",
      "6        3\n",
      "7        1\n",
      "Name: num_question_marks, dtype: int64\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " num_punctuation \n",
      "\n",
      "0     18754\n",
      "1     10638\n",
      "2      7038\n",
      "3      3227\n",
      "4      1515\n",
      "5       538\n",
      "6       289\n",
      "7       115\n",
      "8        49\n",
      "9        17\n",
      "10       10\n",
      "13        7\n",
      "11        5\n",
      "12        4\n",
      "15        3\n",
      "17        1\n",
      "Name: num_punctuation, dtype: int64\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " num_symbols \n",
      "\n",
      "0    39835\n",
      "1     1872\n",
      "2      419\n",
      "4       38\n",
      "3       35\n",
      "6        5\n",
      "8        3\n",
      "5        2\n",
      "7        1\n",
      "Name: num_symbols, dtype: int64\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " total_length \n",
      "\n",
      "31     627\n",
      "22     602\n",
      "41     595\n",
      "38     593\n",
      "23     593\n",
      "      ... \n",
      "232      1\n",
      "168      1\n",
      "167      1\n",
      "260      1\n",
      "207      1\n",
      "Name: total_length, Length: 203, dtype: int64\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " capitals \n",
      "\n",
      "0    42080\n",
      "2      117\n",
      "4        6\n",
      "3        3\n",
      "1        3\n",
      "6        1\n",
      "Name: capitals, dtype: int64\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " caps_vs_length \n",
      "\n",
      "0.000000    42080\n",
      "0.026667        4\n",
      "0.027778        4\n",
      "0.068966        3\n",
      "0.024691        3\n",
      "            ...  \n",
      "0.021739        1\n",
      "0.012500        1\n",
      "0.016949        1\n",
      "0.017391        1\n",
      "0.020000        1\n",
      "Name: caps_vs_length, Length: 93, dtype: int64\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " num_words \n",
      "\n",
      "6     3294\n",
      "5     3290\n",
      "7     3095\n",
      "4     3079\n",
      "8     2954\n",
      "3     2814\n",
      "9     2683\n",
      "10    2483\n",
      "11    2200\n",
      "2     2127\n",
      "12    2054\n",
      "13    1891\n",
      "14    1794\n",
      "15    1540\n",
      "16    1422\n",
      "17    1120\n",
      "18     976\n",
      "1      909\n",
      "19     782\n",
      "20     578\n",
      "21     401\n",
      "22     309\n",
      "23     176\n",
      "24     100\n",
      "25      52\n",
      "26      40\n",
      "27      24\n",
      "28       7\n",
      "29       7\n",
      "31       4\n",
      "30       3\n",
      "34       1\n",
      "32       1\n",
      "Name: num_words, dtype: int64\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " num_unique_words \n",
      "\n",
      "5     3503\n",
      "6     3445\n",
      "7     3295\n",
      "4     3243\n",
      "8     3146\n",
      "3     2984\n",
      "9     2855\n",
      "10    2584\n",
      "11    2292\n",
      "2     2258\n",
      "12    2179\n",
      "13    1932\n",
      "14    1814\n",
      "15    1501\n",
      "16    1257\n",
      "17     974\n",
      "1      947\n",
      "18     804\n",
      "19     512\n",
      "20     321\n",
      "21     186\n",
      "22      92\n",
      "23      47\n",
      "24      14\n",
      "25      14\n",
      "27       5\n",
      "26       3\n",
      "28       2\n",
      "30       1\n",
      "Name: num_unique_words, dtype: int64\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " words_vs_unique \n",
      "\n",
      "1.000000    28441\n",
      "0.875000      875\n",
      "0.888889      870\n",
      "0.900000      841\n",
      "0.857143      820\n",
      "            ...  \n",
      "0.470588        1\n",
      "0.550000        1\n",
      "0.962963        1\n",
      "0.821429        1\n",
      "0.531250        1\n",
      "Name: words_vs_unique, Length: 137, dtype: int64\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in train_data.columns:\n",
    "        print(\"\\n\",c,\"\\n\")\n",
    "        print(train_data[c].value_counts())\n",
    "        print(\"\\n \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8850102669404518"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1,2),max_features=10000)\n",
    "train_tfidf = vec.fit_transform(train_data.tweet)\n",
    "test_tfidf = vec.transform(test_data.tweet)\n",
    "clf.fit(train_tfidf,train_data[\"class\"])\n",
    "predictions = clf.predict(test_tfidf)\n",
    "metrics.f1_score(test_data['class'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "#stemming decreased f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(Path('../dataset/ML_CLEANED_train_data'))\n",
    "test_data.to_csv(Path('../dataset/ML_CLEANED_test_data'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File /home/sandhya/Project/../dataset/ML_CLEANED_train_data does not exist: '/home/sandhya/Project/../dataset/ML_CLEANED_train_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-382-ec3f4ab911a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLEANED_TRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Project/final/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Project/final/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Project/final/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Project/final/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Project/final/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /home/sandhya/Project/../dataset/ML_CLEANED_train_data does not exist: '/home/sandhya/Project/../dataset/ML_CLEANED_train_data'"
     ]
    }
   ],
   "source": [
    "pd.read_csv(CONST.CLEANED_TRAIN).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final",
   "language": "python",
   "name": "final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
