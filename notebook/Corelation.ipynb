{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Corelation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOmqmAycIz8Vp4YiZECFDoD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sandhya-G/Aggression-Detection/blob/master/notebook/Corelation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIOCOZL3TMfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdNH_hNWvsO4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8268ebe0-ca78-4dcb-b5fe-109b3944e14d"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from keras.layers import Dense, Input, Embedding, Dropout, Activation, GRU, Conv1D, concatenate\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
        "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from keras.callbacks import LambdaCallback\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.initializers import *\n",
        "from keras.optimizers import *\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St3X8yorT42V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_objects={'Attention': Attention}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y3SqtGCGx53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#custom attention layer refer the second figure and keras documentation â€˜Writing your own Keras layer'. \n",
        "class Attention(Layer):\n",
        "    #initialise\n",
        "    def __init__(self, step_dim=120,\n",
        "                 W_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Builds all weights\n",
        "        # W = Weight matrix, b = bias vector, u = context vector\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        self.features_dim = input_shape[-1]\n",
        "\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight(shape=(input_shape[1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "        else:\n",
        "            self.b = None\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        #calculations\n",
        "        features_dim = self.features_dim\n",
        "        step_dim = self.step_dim\n",
        "\n",
        "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
        "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
        "\n",
        "        if self.bias:\n",
        "            eij += self.b\n",
        "\n",
        "        eij = K.tanh(eij)\n",
        "\n",
        "        a = K.exp(eij)\n",
        "\n",
        "        if mask is not None:\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0],  self.features_dim\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrO53eRSVpGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import random\n",
        "random.set_seed(2)\n",
        "\n",
        "## split to train and val\n",
        "\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=2048,stratify=train_df[\"class\"])\n",
        "\n",
        "## some config values \n",
        "embed_size = 100 # how big is each word vector\n",
        "max_features = 20000 # how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 100 # max number of words in a question to use\n",
        "\n",
        "## fill up the missing values\n",
        "train_X = train_df[\"tweet\"].fillna(\"_na_\").values\n",
        "val_X = val_df[\"tweet\"].fillna(\"_na_\").values\n",
        "test_X = test_df[\"tweet\"].fillna(\"_na_\").values\n",
        "\n",
        "## Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(train_X))\n",
        "train_X = tokenizer.texts_to_sequences(train_X)\n",
        "val_X = tokenizer.texts_to_sequences(val_X)\n",
        "test_X = tokenizer.texts_to_sequences(test_X)\n",
        "\n",
        "## Pad the sentences \n",
        "train_X = pad_sequences(train_X, maxlen=maxlen,padding='post',truncating='post')\n",
        "val_X = pad_sequences(val_X, maxlen=maxlen,padding='post',truncating='post')\n",
        "test_X = pad_sequences(test_X, maxlen=maxlen,padding='post',truncating='post')\n",
        "\n",
        "## Get the target values\n",
        "train_y = train_df['class'].values\n",
        "val_y = val_df['class'].values\n",
        "test_y = test_df['class'].values\n",
        "\n",
        "\n",
        "        \n",
        "\n"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_gio8qHUCvc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('/content/attention.h5',custom_objects=custom_objects)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfXxyo-QTwEt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e656ae3d-47dc-44c3-d184-4a28ee62fa3f"
      },
      "source": [
        "model = load_model('/content/cnn_text.h5')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "op7GfDWiu91k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_df = pd.read_csv(\"https://raw.githubusercontent.com/Sandhya-G/Aggression-Detection/master/dataset/GLOVE_TRAIN%23\")\n",
        "test_df = pd.read_csv(\"https://raw.githubusercontent.com/Sandhya-G/Aggression-Detection/master/dataset/GLOVE_TEST%23\")"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osNGURHMPppC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = model.predict([test_X])\n",
        "pd.DataFrame(p).to_csv('/content/cnn_text.csv')\n"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx5EzYszv7yy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import random\n",
        "random.set_seed(2)\n",
        "\n",
        "## split to train and val\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=2048,stratify=train_df[\"class\"])\n",
        "\n",
        "## some config values \n",
        "embed_size = 100 # how big is each word vector\n",
        "max_features = 30000 # how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 120 # max number of words in a question to use\n",
        "\n",
        "## fill up the missing values\n",
        "train_X = train_df[\"tweet\"].fillna(\"_na_\").values\n",
        "val_X = val_df[\"tweet\"].fillna(\"_na_\").values\n",
        "test_X = test_df[\"tweet\"].fillna(\"_na_\").values\n",
        "\n",
        "## Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features,filters=\"\")\n",
        "tokenizer.fit_on_texts(list(train_X))\n",
        "train_X = tokenizer.texts_to_sequences(train_X)\n",
        "val_X = tokenizer.texts_to_sequences(val_X)\n",
        "test_X = tokenizer.texts_to_sequences(test_X)\n",
        "\n",
        "## Pad the sentences \n",
        "train_X = pad_sequences(train_X, maxlen=maxlen,padding='post',truncating='post')\n",
        "val_X = pad_sequences(val_X, maxlen=maxlen,padding='post',truncating='post')\n",
        "test_X = pad_sequences(test_X, maxlen=maxlen,padding='post',truncating='post')\n",
        "\n",
        "## Get the target values\n",
        "train_y = train_df['class'].values\n",
        "val_y = val_df['class'].values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOvhJJz1Ce9s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "93caf6b1-8085-47d7-d183-06ee6b54be05"
      },
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "first_file = '/content/attention.csv'\n",
        "second_file = '/content/gru.csv'\n",
        "\n",
        "def corr(first_file, second_file):\n",
        "  first_df = pd.read_csv(first_file,index_col=0)\n",
        "  second_df = pd.read_csv(second_file,index_col=0)\n",
        "  # assuming first column is `prediction_id` and second column is `prediction`\n",
        "  prediction = first_df.columns[0]\n",
        "  # correlation\n",
        "  print(\"Finding correlation between: {} and {}\".format(first_file,second_file))\n",
        "  print(\"Column to be measured: {}\".format(prediction))\n",
        "  #print(\" score: {}\".format(first_df[prediction]))\n",
        "  #print(\" score1: {}\".format(second_df[prediction])\n",
        "  \n",
        "  print(\"Pearson's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='pearson')))\n",
        "  print(\"Kendall's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='kendall')))\n",
        "  print(\"Spearman's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='spearman')))\n",
        "\n",
        "corr(first_file, second_file)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finding correlation between: /content/attention.csv and /content/gru.csv\n",
            "Column to be measured: 0\n",
            "Pearson's correlation score: 0.12292177257573225\n",
            "Kendall's correlation score: 0.15997860780882062\n",
            "Spearman's correlation score: 0.2364503153857585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTM_k20LNGKB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "b0a042ad-a1e5-411e-d6fb-763cc35fb360"
      },
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "first_file = '/content/attention.csv'\n",
        "second_file = '/content/cnn.csv'\n",
        "\n",
        "def corr(first_file, second_file):\n",
        "  first_df = pd.read_csv(first_file,index_col=0)\n",
        "  second_df = pd.read_csv(second_file,index_col=0)\n",
        "  # assuming first column is `prediction_id` and second column is `prediction`\n",
        "  prediction = first_df.columns[0]\n",
        "  # correlation\n",
        "  print(\"Finding correlation between: {} and {}\".format(first_file,second_file))\n",
        "  print(\"Column to be measured: {}\".format(prediction))\n",
        "  print(\"Pearson's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='pearson')))\n",
        "  print(\"Kendall's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='kendall')))\n",
        "  print(\"Spearman's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='spearman')))\n",
        "\n",
        "corr(first_file, second_file)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finding correlation between: /content/attention.csv and /content/cnn.csv\n",
            "Column to be measured: 0\n",
            "Pearson's correlation score: 0.11565194088081888\n",
            "Kendall's correlation score: 0.1361165204597667\n",
            "Spearman's correlation score: 0.20309125425478336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O5BTEV4vYOxR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "3f2edac3-f7c7-445d-f9eb-99e20d075c35"
      },
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "first_file = '/content/gru.csv'\n",
        "second_file = '/content/cnn.csv'\n",
        "\n",
        "def corr(first_file, second_file):\n",
        "  first_df = pd.read_csv(first_file,index_col=0)\n",
        "  second_df = pd.read_csv(second_file,index_col=0)\n",
        "  # assuming first column is `prediction_id` and second column is `prediction`\n",
        "  prediction = first_df.columns[0]\n",
        "  # correlation\n",
        "  print(\"Finding correlation between: {} and {}\".format(first_file,second_file))\n",
        "  print(\"Column to be measured: {}\".format(prediction))\n",
        "  print(\"Pearson's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='pearson')))\n",
        "  print(\"Kendall's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='kendall')))\n",
        "  print(\"Spearman's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='spearman')))\n",
        "\n",
        "corr(first_file, second_file)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finding correlation between: /content/gru.csv and /content/cnn.csv\n",
            "Column to be measured: 0\n",
            "Pearson's correlation score: 0.9183782615552456\n",
            "Kendall's correlation score: 0.7284301225797093\n",
            "Spearman's correlation score: 0.9093209091303897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tmViyQwOSTt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "d8218c80-85d2-4a01-af07-3954168265ee"
      },
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "first_file = '/content/attention.csv'\n",
        "second_file = '/content/cnn1.csv'\n",
        "\n",
        "def corr(first_file, second_file):\n",
        "  first_df = pd.read_csv(first_file,index_col=0)\n",
        "  second_df = pd.read_csv(second_file,index_col=0)\n",
        "  # assuming first column is `prediction_id` and second column is `prediction`\n",
        "  prediction = first_df.columns[0]\n",
        "  # correlation\n",
        "  print(\"Finding correlation between: {} and {}\".format(first_file,second_file))\n",
        "  print(\"Column to be measured: {}\".format(prediction))\n",
        "  print(\"Pearson's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='pearson')))\n",
        "  print(\"Kendall's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='kendall')))\n",
        "  print(\"Spearman's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='spearman')))\n",
        "\n",
        "corr(first_file, second_file)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finding correlation between: /content/attention.csv and /content/cnn1.csv\n",
            "Column to be measured: Unnamed: 1\n",
            "Pearson's correlation score: 0.8968351277718838\n",
            "Kendall's correlation score: 0.9191193905525553\n",
            "Spearman's correlation score: 0.9191254428230831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1aCs62UOb_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "44f2a785-9cf3-4530-ac40-5bed97276f5a"
      },
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "first_file = '/content/gru.csv'\n",
        "second_file = '/content/cnn1.csv'\n",
        "\n",
        "def corr(first_file, second_file):\n",
        "  first_df = pd.read_csv(first_file,index_col=0)\n",
        "  second_df = pd.read_csv(second_file,index_col=0)\n",
        "  # assuming first column is `prediction_id` and second column is `prediction`\n",
        "  prediction = first_df.columns[0]\n",
        "  # correlation\n",
        "  print(\"Finding correlation between: {} and {}\".format(first_file,second_file))\n",
        "  print(\"Column to be measured: {}\".format(prediction))\n",
        "  print(\"Pearson's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='pearson')))\n",
        "  print(\"Kendall's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='kendall')))\n",
        "  print(\"Spearman's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='spearman')))\n",
        "\n",
        "corr(first_file, second_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finding correlation between: /content/gru.csv and /content/cnn1.csv\n",
            "Column to be measured: Unnamed: 1\n",
            "Pearson's correlation score: 0.902049021719535\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l12AYtBtleZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "9653ddd9-0b24-4452-eb94-5570057753a7"
      },
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "first_file = '/content/attention.csv'\n",
        "second_file = '/content/cnn_text.csv'\n",
        "\n",
        "def corr(first_file, second_file):\n",
        "  first_df = pd.read_csv(first_file,index_col=0)\n",
        "  second_df = pd.read_csv(second_file,index_col=0)\n",
        "  # assuming first column is `prediction_id` and second column is `prediction`\n",
        "  prediction = first_df.columns[0]\n",
        "  # correlation\n",
        "  print(\"Finding correlation between: {} and {}\".format(first_file,second_file))\n",
        "  print(\"Column to be measured: {}\".format(prediction))\n",
        "  #print(\" score: {}\".format(first_df[prediction]))\n",
        "  #print(\" score1: {}\".format(second_df[prediction])\n",
        "  \n",
        "  print(\"Pearson's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='pearson')))\n",
        "  print(\"Kendall's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='kendall')))\n",
        "  print(\"Spearman's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='spearman')))\n",
        "\n",
        "corr(first_file, second_file)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finding correlation between: /content/attention.csv and /content/cnn_text.csv\n",
            "Column to be measured: 0\n",
            "Pearson's correlation score: -0.04327056651050293\n",
            "Kendall's correlation score: 0.11626124799034313\n",
            "Spearman's correlation score: 0.17753628368694008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxcMLrrdlnoQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "7c685036-903d-49b6-c4e4-21b3371e192b"
      },
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "first_file = '/content/gru.csv'\n",
        "second_file = '/content/cnn_text.csv'\n",
        "\n",
        "def corr(first_file, second_file):\n",
        "  first_df = pd.read_csv(first_file,index_col=0)\n",
        "  second_df = pd.read_csv(second_file,index_col=0)\n",
        "  # assuming first column is `prediction_id` and second column is `prediction`\n",
        "  prediction = first_df.columns[0]\n",
        "  # correlation\n",
        "  print(\"Finding correlation between: {} and {}\".format(first_file,second_file))\n",
        "  print(\"Column to be measured: {}\".format(prediction))\n",
        "  #print(\" score: {}\".format(first_df[prediction]))\n",
        "  #print(\" score1: {}\".format(second_df[prediction])\n",
        "  \n",
        "  print(\"Pearson's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='pearson')))\n",
        "  print(\"Kendall's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='kendall')))\n",
        "  print(\"Spearman's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='spearman')))\n",
        "\n",
        "corr(first_file, second_file)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finding correlation between: /content/gru.csv and /content/cnn_text.csv\n",
            "Column to be measured: 0\n",
            "Pearson's correlation score: 0.10524120585500138\n",
            "Kendall's correlation score: 0.2891194596411396\n",
            "Spearman's correlation score: 0.4386581267451317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz-5XIChlxBk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "a0560716-b9ce-4f58-a7a4-9168d5d2a426"
      },
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "first_file = '/content/cnn.csv'\n",
        "second_file = '/content/cnn_text.csv'\n",
        "\n",
        "def corr(first_file, second_file):\n",
        "  first_df = pd.read_csv(first_file,index_col=0)\n",
        "  second_df = pd.read_csv(second_file,index_col=0)\n",
        "  # assuming first column is `prediction_id` and second column is `prediction`\n",
        "  prediction = first_df.columns[0]\n",
        "  # correlation\n",
        "  print(\"Finding correlation between: {} and {}\".format(first_file,second_file))\n",
        "  print(\"Column to be measured: {}\".format(prediction))\n",
        "  #print(\" score: {}\".format(first_df[prediction]))\n",
        "  #print(\" score1: {}\".format(second_df[prediction])\n",
        "  \n",
        "  print(\"Pearson's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='pearson')))\n",
        "  print(\"Kendall's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='kendall')))\n",
        "  print(\"Spearman's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='spearman')))\n",
        "\n",
        "corr(first_file, second_file)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finding correlation between: /content/cnn.csv and /content/cnn_text.csv\n",
            "Column to be measured: 0\n",
            "Pearson's correlation score: 0.10438494501230992\n",
            "Kendall's correlation score: 0.2883153422521823\n",
            "Spearman's correlation score: 0.4296728248524211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czXs_G9HhrXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_result(text):\n",
        "  val = tokenizer.texts_to_sequences([text])\n",
        "  val = pad_sequences(val, maxlen=maxlen,padding='post',truncating='post')\n",
        "  return model.predict(val)[0]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5iw820HExDm",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cm1pGpMU01m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cee92a9-e624-4345-eaa4-3b1ed3f8d7a1"
      },
      "source": [
        "predict_result(\"That is fucking good\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.17055526], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJb2NVaVW5Ak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e74a7514-c59b-47b5-8694-f1495a70a095"
      },
      "source": [
        "predict_result(\"black lives matter\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.11282898], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCTsIoX9XjYs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "888f1220-510d-4030-883b-53a5163c65a9"
      },
      "source": [
        "predict_result(\"you suck\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.61150247], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S254-slHYdh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}